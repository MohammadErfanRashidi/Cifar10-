{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2662a5",
   "metadata": {},
   "source": [
    "# CIFAR-10 Colab Notebook\n",
    "This notebook demonstrates how to download, process, and use the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec72bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the Kaggle API to download datasets\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Kaggle API key\n",
    "!mkdir -p ~/.kaggle  # Create a directory for the API key\n",
    "!cp kaggle.json ~/.kaggle/  # Copy the Kaggle API key to the directory\n",
    "!chmod 600 ~/.kaggle/kaggle.json  # Secure the API key file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the CIFAR-10 dataset from Kaggle\n",
    "!kaggle competitions download -c cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the downloaded files\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the CIFAR-10 dataset\n",
    "from zipfile import ZipFile\n",
    "dataset = '/content/cifar-10.zip'  # Path to the zip file\n",
    "\n",
    "with ZipFile(dataset, 'r') as zip:\n",
    "    zip.extractall()  # Extract all contents of the zip file\n",
    "    print('The dataset is extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the extracted contents\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56332c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing py7zr for handling 7z compressed files\n",
    "!pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the train.7z file\n",
    "import py7zr\n",
    "\n",
    "archive = py7zr.SevenZipFile('/content/train.7z', mode='r')  # Opening the archive\n",
    "archive.extractall()  # Extracting all contents\n",
    "archive.close()  # Closing the archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3428ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying extracted files again\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f43b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image  # For image processing\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import matplotlib.image as mpimg  # For loading images\n",
    "from sklearn.model_selection import train_test_split  # For splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fb2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all image filenames in the train folder\n",
    "filenames = os.listdir('/content/train')\n",
    "print(len(filenames))  # Printing the number of files\n",
    "print(filenames[0:5])  # Displaying a sample of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a901f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading labels from the CSV file\n",
    "labels_df = pd.read_csv('/content/trainLabels.csv')\n",
    "\n",
    "# Inspecting the labels dataset\n",
    "print(labels_df.shape)  # Shape of the labels dataset\n",
    "print(labels_df.head())  # First 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70198bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping string labels to numerical values\n",
    "labels_dictionary = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3,\n",
    "                     'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "labels = [labels_dictionary[i] for i in labels_df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56844bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing a sample image\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow  # For displaying images in Colab\n",
    "\n",
    "img = cv2.imread('/content/train/7796.png')  # Loading an image\n",
    "cv2_imshow(img)  # Displaying the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cccfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting images to NumPy arrays for processing\n",
    "train_data_folder = '/content/train/'\n",
    "data = []\n",
    "\n",
    "for id in labels_df['id']:\n",
    "    image = Image.open(train_data_folder + str(id) + '.png')  # Load image\n",
    "    image = np.array(image)  # Convert to NumPy array\n",
    "    data.append(image)  # Append to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60bc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the list of images and labels to NumPy arrays\n",
    "X = np.array(data)  # Features\n",
    "Y = np.array(labels)  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debdd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data by normalizing pixel values to [0, 1]\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5406c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a basic neural network model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "num_of_classes = 10\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32, 32, 3)),  # Flatten the input images\n",
    "    keras.layers.Dense(64, activation='relu'),  # Dense layer with ReLU activation\n",
    "    keras.layers.Dense(num_of_classes, activation='softmax')  # Output layer with Softmax\n",
    "])\n",
    "\n",
    "# Compiling the neural network\n",
    "model.compile(optimizer='adam',  # Optimizer\n",
    "              loss='sparse_categorical_crossentropy',  # Loss function\n",
    "              metrics=['acc'])  # Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294eabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the neural network\n",
    "model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69eede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing transfer learning using ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "\n",
    "convolutional_base = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Building a new model on top of ResNet50\n",
    "model = models.Sequential([\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.UpSampling2D((2, 2)),\n",
    "    layers.UpSampling2D((2, 2)),  # Upsample to match ResNet input\n",
    "    convolutional_base,  # Pre-trained ResNet\n",
    "    layers.Flatten(),  # Flatten features\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(num_of_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compiling the ResNet-based model\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879df5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the ResNet-based model\n",
    "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
    "print('Test Accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f3371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation accuracy\n",
    "plt.plot(history.history['acc'], label='train accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}